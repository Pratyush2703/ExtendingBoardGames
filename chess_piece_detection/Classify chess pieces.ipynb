{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "J9Je0gsCod31",
    "outputId": "8833dd6e-a3e5-4069-d317-ef5357e87427"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "## Below code required to access Google drive resources\n",
    "# Load the Drive helper and mount\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AOORH4OBo7eT"
   },
   "outputs": [],
   "source": [
    "# Keras and TF imports\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6oYjHJlHpRk1"
   },
   "outputs": [],
   "source": [
    "# Scikit-learn and Numpy imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VzI16CRFpmG_"
   },
   "outputs": [],
   "source": [
    "# set the location of the training and test images (change as required)\n",
    "location_of_train_data = \"../../Chess ID Public Data/output_train\"\n",
    "location_of_test_data = \"../../Chess ID Public Data/output_test\"\n",
    "model_folder_name = \"../models/15_12\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bQvSOos5sFxt"
   },
   "outputs": [],
   "source": [
    "class_names = [\"bishop\", \"king\", \"knight\", \"pawn\", \"queen\", \"rook\", \"empty\"]\n",
    "class_names_reverse_mappings = {\"bishop\": 0, \"king\": 1, \"knight\":2, \"pawn\":3, \"queen\":4, \"rook\":5, \"empty\":6}\n",
    "class_names_folder_mappings = {\"bishop\": [\"bb\", \"wb\"], \"king\": [\"bk\", \"wk\"], \"knight\":[\"bn\", \"wn\"], \"pawn\":[\"bp\", \"wp\"], \"queen\":[\"bq\", \"wq\"], \"rook\":[\"br\", \"wr\"], \"empty\":[\"empty\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y60PmbgeqnfW"
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n",
    "def get_required_data_with_labels_for_model(base_location, num_samples = None, dimensions=(299, 299)):\n",
    "  X, y = [], []\n",
    "  for class_name in class_names_folder_mappings:\n",
    "    for folder_name in class_names_folder_mappings[class_name]:\n",
    "      complete_path = os.path.join(base_location, folder_name)\n",
    "      print(\"Reading the files from the location {0}\".format(complete_path))\n",
    "      current_samples = 0\n",
    "      for image_file_name in os.listdir(complete_path):\n",
    "        \n",
    "        # check if the current file is an image file with jpg extension\n",
    "        if image_file_name.endswith(\".jpg\"):\n",
    "          current_samples += 1\n",
    "          img_path = os.path.join(complete_path, image_file_name)\n",
    "          \n",
    "          # basic pre-processing of the images\n",
    "          img = image.load_img(img_path, target_size=dimensions)\n",
    "          x = image.img_to_array(img)\n",
    "          x = preprocess_input(x)\n",
    "          \n",
    "          X.append(x)\n",
    "          class_name_id = class_names_reverse_mappings[class_name]\n",
    "          y.append(class_name_id)\n",
    "        \n",
    "          if ((num_samples is not None) and (current_samples == num_samples)):\n",
    "            break\n",
    "  \n",
    "  return X, y    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "v0pQBq7JxJNz",
    "outputId": "b65cfba0-3156-4c84-eaa7-8634786e77a9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the files from the location ../../Chess ID Public Data/output_train\\bb\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wb\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\bk\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wk\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\bn\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wn\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\bp\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wp\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\bq\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wq\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\br\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\wr\n",
      "Reading the files from the location ../../Chess ID Public Data/output_train\\empty\n",
      "10360\n",
      "10360\n",
      "(299, 299, 3)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X, y = get_required_data_with_labels_for_model(location_of_train_data)\n",
    "print(len(X))\n",
    "print(len(y))\n",
    "print(X[0].shape)\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xGk0wJqayDc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9324, 299, 299, 3)\n",
      "(1036, 299, 299, 3)\n",
      "9324\n",
      "1036\n"
     ]
    }
   ],
   "source": [
    "# X_test, y_test = get_required_data_with_labels_for_model(location_of_test_data)\n",
    "X = np.array(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fYSfIyAjzMWx"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, None, None, 3 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, None, None, 3 864         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_377 (BatchN (None, None, None, 3 96          conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_377 (Activation)     (None, None, None, 3 0           batch_normalization_377[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, None, None, 3 9216        activation_377[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_378 (BatchN (None, None, None, 3 96          conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_378 (Activation)     (None, None, None, 3 0           batch_normalization_378[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, None, None, 6 18432       activation_378[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_379 (BatchN (None, None, None, 6 192         conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_379 (Activation)     (None, None, None, 6 0           batch_normalization_379[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling2D) (None, None, None, 6 0           activation_379[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, None, None, 8 5120        max_pooling2d_17[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_380 (BatchN (None, None, None, 8 240         conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_380 (Activation)     (None, None, None, 8 0           batch_normalization_380[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, None, None, 1 138240      activation_380[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_381 (BatchN (None, None, None, 1 576         conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_381 (Activation)     (None, None, None, 1 0           batch_normalization_381[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling2D) (None, None, None, 1 0           activation_381[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_385 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_385 (BatchN (None, None, None, 6 192         conv2d_385[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_385 (Activation)     (None, None, None, 6 0           batch_normalization_385[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, None, None, 4 9216        max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_386 (Conv2D)             (None, None, None, 9 55296       activation_385[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_383 (BatchN (None, None, None, 4 144         conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_386 (BatchN (None, None, None, 9 288         conv2d_386[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_383 (Activation)     (None, None, None, 4 0           batch_normalization_383[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_386 (Activation)     (None, None, None, 9 0           batch_normalization_386[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_37 (AveragePo (None, None, None, 1 0           max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, None, None, 6 12288       max_pooling2d_18[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, None, None, 6 76800       activation_383[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_387 (Conv2D)             (None, None, None, 9 82944       activation_386[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_388 (Conv2D)             (None, None, None, 3 6144        average_pooling2d_37[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_382 (BatchN (None, None, None, 6 192         conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_384 (BatchN (None, None, None, 6 192         conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_387 (BatchN (None, None, None, 9 288         conv2d_387[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_388 (BatchN (None, None, None, 3 96          conv2d_388[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_382 (Activation)     (None, None, None, 6 0           batch_normalization_382[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_384 (Activation)     (None, None, None, 6 0           batch_normalization_384[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_387 (Activation)     (None, None, None, 9 0           batch_normalization_387[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_388 (Activation)     (None, None, None, 3 0           batch_normalization_388[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, None, None, 2 0           activation_382[0][0]             \n",
      "                                                                 activation_384[0][0]             \n",
      "                                                                 activation_387[0][0]             \n",
      "                                                                 activation_388[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_392 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_392 (BatchN (None, None, None, 6 192         conv2d_392[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_392 (Activation)     (None, None, None, 6 0           batch_normalization_392[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_390 (Conv2D)             (None, None, None, 4 12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_393 (Conv2D)             (None, None, None, 9 55296       activation_392[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_390 (BatchN (None, None, None, 4 144         conv2d_390[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_393 (BatchN (None, None, None, 9 288         conv2d_393[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_390 (Activation)     (None, None, None, 4 0           batch_normalization_390[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_393 (Activation)     (None, None, None, 9 0           batch_normalization_393[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_38 (AveragePo (None, None, None, 2 0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_389 (Conv2D)             (None, None, None, 6 16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_391 (Conv2D)             (None, None, None, 6 76800       activation_390[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_394 (Conv2D)             (None, None, None, 9 82944       activation_393[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_395 (Conv2D)             (None, None, None, 6 16384       average_pooling2d_38[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_389 (BatchN (None, None, None, 6 192         conv2d_389[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_391 (BatchN (None, None, None, 6 192         conv2d_391[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_394 (BatchN (None, None, None, 9 288         conv2d_394[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_395 (BatchN (None, None, None, 6 192         conv2d_395[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_389 (Activation)     (None, None, None, 6 0           batch_normalization_389[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_391 (Activation)     (None, None, None, 6 0           batch_normalization_391[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_394 (Activation)     (None, None, None, 9 0           batch_normalization_394[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_395 (Activation)     (None, None, None, 6 0           batch_normalization_395[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, None, None, 2 0           activation_389[0][0]             \n",
      "                                                                 activation_391[0][0]             \n",
      "                                                                 activation_394[0][0]             \n",
      "                                                                 activation_395[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_399 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_399 (BatchN (None, None, None, 6 192         conv2d_399[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_399 (Activation)     (None, None, None, 6 0           batch_normalization_399[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_397 (Conv2D)             (None, None, None, 4 13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_400 (Conv2D)             (None, None, None, 9 55296       activation_399[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_397 (BatchN (None, None, None, 4 144         conv2d_397[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_400 (BatchN (None, None, None, 9 288         conv2d_400[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_397 (Activation)     (None, None, None, 4 0           batch_normalization_397[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_400 (Activation)     (None, None, None, 9 0           batch_normalization_400[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_39 (AveragePo (None, None, None, 2 0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_396 (Conv2D)             (None, None, None, 6 18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_398 (Conv2D)             (None, None, None, 6 76800       activation_397[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_401 (Conv2D)             (None, None, None, 9 82944       activation_400[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_402 (Conv2D)             (None, None, None, 6 18432       average_pooling2d_39[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_396 (BatchN (None, None, None, 6 192         conv2d_396[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_398 (BatchN (None, None, None, 6 192         conv2d_398[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_401 (BatchN (None, None, None, 9 288         conv2d_401[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_402 (BatchN (None, None, None, 6 192         conv2d_402[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_396 (Activation)     (None, None, None, 6 0           batch_normalization_396[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_398 (Activation)     (None, None, None, 6 0           batch_normalization_398[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_401 (Activation)     (None, None, None, 9 0           batch_normalization_401[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_402 (Activation)     (None, None, None, 6 0           batch_normalization_402[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, None, None, 2 0           activation_396[0][0]             \n",
      "                                                                 activation_398[0][0]             \n",
      "                                                                 activation_401[0][0]             \n",
      "                                                                 activation_402[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_404 (Conv2D)             (None, None, None, 6 18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, None, None, 6 192         conv2d_404[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_404 (Activation)     (None, None, None, 6 0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_405 (Conv2D)             (None, None, None, 9 55296       activation_404[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, None, None, 9 288         conv2d_405[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_405 (Activation)     (None, None, None, 9 0           batch_normalization_405[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_403 (Conv2D)             (None, None, None, 3 995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_406 (Conv2D)             (None, None, None, 9 82944       activation_405[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, None, None, 3 1152        conv2d_403[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, None, None, 9 288         conv2d_406[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_403 (Activation)     (None, None, None, 3 0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_406 (Activation)     (None, None, None, 9 0           batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling2D) (None, None, None, 2 0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, None, None, 7 0           activation_403[0][0]             \n",
      "                                                                 activation_406[0][0]             \n",
      "                                                                 max_pooling2d_19[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_411 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, None, None, 1 384         conv2d_411[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_411 (Activation)     (None, None, None, 1 0           batch_normalization_411[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_412 (Conv2D)             (None, None, None, 1 114688      activation_411[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, None, None, 1 384         conv2d_412[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_412 (Activation)     (None, None, None, 1 0           batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_408 (Conv2D)             (None, None, None, 1 98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_413 (Conv2D)             (None, None, None, 1 114688      activation_412[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, None, None, 1 384         conv2d_408[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, None, None, 1 384         conv2d_413[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_408 (Activation)     (None, None, None, 1 0           batch_normalization_408[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_413 (Activation)     (None, None, None, 1 0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_409 (Conv2D)             (None, None, None, 1 114688      activation_408[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_414 (Conv2D)             (None, None, None, 1 114688      activation_413[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, None, None, 1 384         conv2d_409[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, None, None, 1 384         conv2d_414[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_409 (Activation)     (None, None, None, 1 0           batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_414 (Activation)     (None, None, None, 1 0           batch_normalization_414[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_40 (AveragePo (None, None, None, 7 0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_407 (Conv2D)             (None, None, None, 1 147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_410 (Conv2D)             (None, None, None, 1 172032      activation_409[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_415 (Conv2D)             (None, None, None, 1 172032      activation_414[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_416 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_40[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, None, None, 1 576         conv2d_407[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, None, None, 1 576         conv2d_410[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, None, None, 1 576         conv2d_415[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, None, None, 1 576         conv2d_416[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_407 (Activation)     (None, None, None, 1 0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_410 (Activation)     (None, None, None, 1 0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_415 (Activation)     (None, None, None, 1 0           batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_416 (Activation)     (None, None, None, 1 0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, None, None, 7 0           activation_407[0][0]             \n",
      "                                                                 activation_410[0][0]             \n",
      "                                                                 activation_415[0][0]             \n",
      "                                                                 activation_416[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_421 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, None, None, 1 480         conv2d_421[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_421 (Activation)     (None, None, None, 1 0           batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_422 (Conv2D)             (None, None, None, 1 179200      activation_421[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, None, None, 1 480         conv2d_422[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_422 (Activation)     (None, None, None, 1 0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_418 (Conv2D)             (None, None, None, 1 122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_423 (Conv2D)             (None, None, None, 1 179200      activation_422[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, None, None, 1 480         conv2d_418[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, None, None, 1 480         conv2d_423[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_418 (Activation)     (None, None, None, 1 0           batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_423 (Activation)     (None, None, None, 1 0           batch_normalization_423[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_419 (Conv2D)             (None, None, None, 1 179200      activation_418[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_424 (Conv2D)             (None, None, None, 1 179200      activation_423[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, None, None, 1 480         conv2d_419[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, None, None, 1 480         conv2d_424[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_419 (Activation)     (None, None, None, 1 0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_424 (Activation)     (None, None, None, 1 0           batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_41 (AveragePo (None, None, None, 7 0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_417 (Conv2D)             (None, None, None, 1 147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_420 (Conv2D)             (None, None, None, 1 215040      activation_419[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_425 (Conv2D)             (None, None, None, 1 215040      activation_424[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_426 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_41[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, None, None, 1 576         conv2d_417[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, None, None, 1 576         conv2d_420[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, None, None, 1 576         conv2d_425[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, None, None, 1 576         conv2d_426[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_417 (Activation)     (None, None, None, 1 0           batch_normalization_417[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_420 (Activation)     (None, None, None, 1 0           batch_normalization_420[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_425 (Activation)     (None, None, None, 1 0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_426 (Activation)     (None, None, None, 1 0           batch_normalization_426[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, None, None, 7 0           activation_417[0][0]             \n",
      "                                                                 activation_420[0][0]             \n",
      "                                                                 activation_425[0][0]             \n",
      "                                                                 activation_426[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_431 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, None, None, 1 480         conv2d_431[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_431 (Activation)     (None, None, None, 1 0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_432 (Conv2D)             (None, None, None, 1 179200      activation_431[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, None, None, 1 480         conv2d_432[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_432 (Activation)     (None, None, None, 1 0           batch_normalization_432[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_428 (Conv2D)             (None, None, None, 1 122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_433 (Conv2D)             (None, None, None, 1 179200      activation_432[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, None, None, 1 480         conv2d_428[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, None, None, 1 480         conv2d_433[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_428 (Activation)     (None, None, None, 1 0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_433 (Activation)     (None, None, None, 1 0           batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_429 (Conv2D)             (None, None, None, 1 179200      activation_428[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_434 (Conv2D)             (None, None, None, 1 179200      activation_433[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, None, None, 1 480         conv2d_429[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, None, None, 1 480         conv2d_434[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_429 (Activation)     (None, None, None, 1 0           batch_normalization_429[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_434 (Activation)     (None, None, None, 1 0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_42 (AveragePo (None, None, None, 7 0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_427 (Conv2D)             (None, None, None, 1 147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_430 (Conv2D)             (None, None, None, 1 215040      activation_429[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_435 (Conv2D)             (None, None, None, 1 215040      activation_434[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_436 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_42[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, None, None, 1 576         conv2d_427[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, None, None, 1 576         conv2d_430[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, None, None, 1 576         conv2d_435[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, None, None, 1 576         conv2d_436[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_427 (Activation)     (None, None, None, 1 0           batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_430 (Activation)     (None, None, None, 1 0           batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_435 (Activation)     (None, None, None, 1 0           batch_normalization_435[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_436 (Activation)     (None, None, None, 1 0           batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, None, None, 7 0           activation_427[0][0]             \n",
      "                                                                 activation_430[0][0]             \n",
      "                                                                 activation_435[0][0]             \n",
      "                                                                 activation_436[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_441 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, None, None, 1 576         conv2d_441[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_441 (Activation)     (None, None, None, 1 0           batch_normalization_441[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_442 (Conv2D)             (None, None, None, 1 258048      activation_441[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, None, None, 1 576         conv2d_442[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_442 (Activation)     (None, None, None, 1 0           batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_438 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_443 (Conv2D)             (None, None, None, 1 258048      activation_442[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, None, None, 1 576         conv2d_438[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, None, None, 1 576         conv2d_443[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_438 (Activation)     (None, None, None, 1 0           batch_normalization_438[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_443 (Activation)     (None, None, None, 1 0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_439 (Conv2D)             (None, None, None, 1 258048      activation_438[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_444 (Conv2D)             (None, None, None, 1 258048      activation_443[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, None, None, 1 576         conv2d_439[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, None, None, 1 576         conv2d_444[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_439 (Activation)     (None, None, None, 1 0           batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_444 (Activation)     (None, None, None, 1 0           batch_normalization_444[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_43 (AveragePo (None, None, None, 7 0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_437 (Conv2D)             (None, None, None, 1 147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_440 (Conv2D)             (None, None, None, 1 258048      activation_439[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_445 (Conv2D)             (None, None, None, 1 258048      activation_444[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_446 (Conv2D)             (None, None, None, 1 147456      average_pooling2d_43[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, None, None, 1 576         conv2d_437[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, None, None, 1 576         conv2d_440[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, None, None, 1 576         conv2d_445[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, None, None, 1 576         conv2d_446[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_437 (Activation)     (None, None, None, 1 0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_440 (Activation)     (None, None, None, 1 0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_445 (Activation)     (None, None, None, 1 0           batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_446 (Activation)     (None, None, None, 1 0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, None, None, 7 0           activation_437[0][0]             \n",
      "                                                                 activation_440[0][0]             \n",
      "                                                                 activation_445[0][0]             \n",
      "                                                                 activation_446[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_449 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, None, None, 1 576         conv2d_449[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_449 (Activation)     (None, None, None, 1 0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_450 (Conv2D)             (None, None, None, 1 258048      activation_449[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, None, None, 1 576         conv2d_450[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_450 (Activation)     (None, None, None, 1 0           batch_normalization_450[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_447 (Conv2D)             (None, None, None, 1 147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_451 (Conv2D)             (None, None, None, 1 258048      activation_450[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, None, None, 1 576         conv2d_447[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, None, None, 1 576         conv2d_451[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_447 (Activation)     (None, None, None, 1 0           batch_normalization_447[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_451 (Activation)     (None, None, None, 1 0           batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_448 (Conv2D)             (None, None, None, 3 552960      activation_447[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_452 (Conv2D)             (None, None, None, 1 331776      activation_451[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, None, None, 3 960         conv2d_448[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_452 (BatchN (None, None, None, 1 576         conv2d_452[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_448 (Activation)     (None, None, None, 3 0           batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_452 (Activation)     (None, None, None, 1 0           batch_normalization_452[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling2D) (None, None, None, 7 0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, None, None, 1 0           activation_448[0][0]             \n",
      "                                                                 activation_452[0][0]             \n",
      "                                                                 max_pooling2d_20[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_457 (Conv2D)             (None, None, None, 4 573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_457 (BatchN (None, None, None, 4 1344        conv2d_457[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_457 (Activation)     (None, None, None, 4 0           batch_normalization_457[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_454 (Conv2D)             (None, None, None, 3 491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_458 (Conv2D)             (None, None, None, 3 1548288     activation_457[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_454 (BatchN (None, None, None, 3 1152        conv2d_454[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_458 (BatchN (None, None, None, 3 1152        conv2d_458[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_454 (Activation)     (None, None, None, 3 0           batch_normalization_454[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_458 (Activation)     (None, None, None, 3 0           batch_normalization_458[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_455 (Conv2D)             (None, None, None, 3 442368      activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_456 (Conv2D)             (None, None, None, 3 442368      activation_454[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_459 (Conv2D)             (None, None, None, 3 442368      activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_460 (Conv2D)             (None, None, None, 3 442368      activation_458[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_44 (AveragePo (None, None, None, 1 0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_453 (Conv2D)             (None, None, None, 3 409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_455 (BatchN (None, None, None, 3 1152        conv2d_455[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_456 (BatchN (None, None, None, 3 1152        conv2d_456[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_459 (BatchN (None, None, None, 3 1152        conv2d_459[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_460 (BatchN (None, None, None, 3 1152        conv2d_460[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_461 (Conv2D)             (None, None, None, 1 245760      average_pooling2d_44[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_453 (BatchN (None, None, None, 3 960         conv2d_453[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_455 (Activation)     (None, None, None, 3 0           batch_normalization_455[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_456 (Activation)     (None, None, None, 3 0           batch_normalization_456[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_459 (Activation)     (None, None, None, 3 0           batch_normalization_459[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_460 (Activation)     (None, None, None, 3 0           batch_normalization_460[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_461 (BatchN (None, None, None, 1 576         conv2d_461[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_453 (Activation)     (None, None, None, 3 0           batch_normalization_453[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_455[0][0]             \n",
      "                                                                 activation_456[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_9 (Concatenate)     (None, None, None, 7 0           activation_459[0][0]             \n",
      "                                                                 activation_460[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_461 (Activation)     (None, None, None, 1 0           batch_normalization_461[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, None, None, 2 0           activation_453[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_9[0][0]              \n",
      "                                                                 activation_461[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_466 (Conv2D)             (None, None, None, 4 917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_466 (BatchN (None, None, None, 4 1344        conv2d_466[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_466 (Activation)     (None, None, None, 4 0           batch_normalization_466[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_463 (Conv2D)             (None, None, None, 3 786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_467 (Conv2D)             (None, None, None, 3 1548288     activation_466[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_463 (BatchN (None, None, None, 3 1152        conv2d_463[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_467 (BatchN (None, None, None, 3 1152        conv2d_467[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_463 (Activation)     (None, None, None, 3 0           batch_normalization_463[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_467 (Activation)     (None, None, None, 3 0           batch_normalization_467[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_464 (Conv2D)             (None, None, None, 3 442368      activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_465 (Conv2D)             (None, None, None, 3 442368      activation_463[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_468 (Conv2D)             (None, None, None, 3 442368      activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_469 (Conv2D)             (None, None, None, 3 442368      activation_467[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_45 (AveragePo (None, None, None, 2 0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_462 (Conv2D)             (None, None, None, 3 655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_464 (BatchN (None, None, None, 3 1152        conv2d_464[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_465 (BatchN (None, None, None, 3 1152        conv2d_465[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_468 (BatchN (None, None, None, 3 1152        conv2d_468[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_469 (BatchN (None, None, None, 3 1152        conv2d_469[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_470 (Conv2D)             (None, None, None, 1 393216      average_pooling2d_45[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_462 (BatchN (None, None, None, 3 960         conv2d_462[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_464 (Activation)     (None, None, None, 3 0           batch_normalization_464[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_465 (Activation)     (None, None, None, 3 0           batch_normalization_465[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_468 (Activation)     (None, None, None, 3 0           batch_normalization_468[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_469 (Activation)     (None, None, None, 3 0           batch_normalization_469[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_470 (BatchN (None, None, None, 1 576         conv2d_470[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_462 (Activation)     (None, None, None, 3 0           batch_normalization_462[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_464[0][0]             \n",
      "                                                                 activation_465[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_10 (Concatenate)    (None, None, None, 7 0           activation_468[0][0]             \n",
      "                                                                 activation_469[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_470 (Activation)     (None, None, None, 1 0           batch_normalization_470[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, None, None, 2 0           activation_462[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_10[0][0]             \n",
      "                                                                 activation_470[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1024)         2098176     global_average_pooling2d_5[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 7)            7175        dense_9[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,908,135\n",
      "Trainable params: 2,105,351\n",
      "Non-trainable params: 21,802,784\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## update the base inception v3 model\n",
    "\n",
    "num_output_classes = len(class_names)\n",
    "\n",
    "# create the base pre-trained model\n",
    "inception_v3_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = inception_v3_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(num_output_classes, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=inception_v3_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in inception_v3_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "opt = RMSprop(lr=0.00001)\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(model_folder_name):\n",
    "    os.makedirs(model_folder_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3bjewU2s2SnH"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=os.path.join(model_folder_name, \"chess_pieces_inceptionv3_p1.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=100, min_delta= 0.0001)\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zYzNRVKP3I7P"
   },
   "outputs": [],
   "source": [
    "epochs = 500\n",
    "batch_size = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mrfa8W7P3B3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9324 samples, validate on 1036 samples\n",
      "Epoch 1/500\n",
      "9324/9324 [==============================] - 41s 4ms/step - loss: 1.5518 - acc: 0.5446 - val_loss: 1.5538 - val_acc: 0.5975\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.59749, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 2/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 1.2065 - acc: 0.6229 - val_loss: 1.4070 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.59749 to 0.60618, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 3/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 1.0056 - acc: 0.6608 - val_loss: 1.3422 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00003: val_acc did not improve from 0.60618\n",
      "Epoch 4/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.8641 - acc: 0.7177 - val_loss: 1.2834 - val_acc: 0.6062\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.60618\n",
      "Epoch 5/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.7614 - acc: 0.7713 - val_loss: 1.2384 - val_acc: 0.6071\n",
      "\n",
      "Epoch 00005: val_acc improved from 0.60618 to 0.60714, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 6/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.6783 - acc: 0.8093 - val_loss: 1.2779 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00006: val_acc improved from 0.60714 to 0.61100, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 7/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.6123 - acc: 0.8384 - val_loss: 1.3061 - val_acc: 0.6110\n",
      "\n",
      "Epoch 00007: val_acc did not improve from 0.61100\n",
      "Epoch 8/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.5582 - acc: 0.8611 - val_loss: 1.3049 - val_acc: 0.6139\n",
      "\n",
      "Epoch 00008: val_acc improved from 0.61100 to 0.61390, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 9/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.5151 - acc: 0.8749 - val_loss: 1.3868 - val_acc: 0.6129\n",
      "\n",
      "Epoch 00009: val_acc did not improve from 0.61390\n",
      "Epoch 10/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.4777 - acc: 0.8866 - val_loss: 1.3475 - val_acc: 0.6226\n",
      "\n",
      "Epoch 00010: val_acc improved from 0.61390 to 0.62259, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 11/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.4435 - acc: 0.8952 - val_loss: 1.3135 - val_acc: 0.6332\n",
      "\n",
      "Epoch 00011: val_acc improved from 0.62259 to 0.63320, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 12/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.4129 - acc: 0.9037 - val_loss: 1.3830 - val_acc: 0.6293\n",
      "\n",
      "Epoch 00012: val_acc did not improve from 0.63320\n",
      "Epoch 13/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.3907 - acc: 0.9079 - val_loss: 1.4355 - val_acc: 0.6332\n",
      "\n",
      "Epoch 00013: val_acc improved from 0.63320 to 0.63320, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 14/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.3670 - acc: 0.9157 - val_loss: 1.5092 - val_acc: 0.6284\n",
      "\n",
      "Epoch 00014: val_acc did not improve from 0.63320\n",
      "Epoch 15/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.3482 - acc: 0.9195 - val_loss: 1.4418 - val_acc: 0.6351\n",
      "\n",
      "Epoch 00015: val_acc improved from 0.63320 to 0.63514, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 16/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.3314 - acc: 0.9234 - val_loss: 1.5043 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00016: val_acc improved from 0.63514 to 0.63803, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 17/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.3138 - acc: 0.9269 - val_loss: 1.5607 - val_acc: 0.6351\n",
      "\n",
      "Epoch 00017: val_acc did not improve from 0.63803\n",
      "Epoch 18/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.3004 - acc: 0.9304 - val_loss: 1.5728 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00018: val_acc did not improve from 0.63803\n",
      "Epoch 19/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2872 - acc: 0.9348 - val_loss: 1.5962 - val_acc: 0.6371\n",
      "\n",
      "Epoch 00019: val_acc did not improve from 0.63803\n",
      "Epoch 20/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2777 - acc: 0.9355 - val_loss: 1.5728 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00020: val_acc improved from 0.63803 to 0.63996, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 21/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.2667 - acc: 0.9373 - val_loss: 1.6302 - val_acc: 0.6390\n",
      "\n",
      "Epoch 00021: val_acc did not improve from 0.63996\n",
      "Epoch 22/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.2581 - acc: 0.9399 - val_loss: 1.6165 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00022: val_acc improved from 0.63996 to 0.64093, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 23/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.2467 - acc: 0.9434 - val_loss: 1.8469 - val_acc: 0.6293\n",
      "\n",
      "Epoch 00023: val_acc did not improve from 0.64093\n",
      "Epoch 24/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2381 - acc: 0.9420 - val_loss: 1.6478 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00024: val_acc improved from 0.64093 to 0.64479, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 25/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2322 - acc: 0.9458 - val_loss: 1.7134 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00025: val_acc did not improve from 0.64479\n",
      "Epoch 26/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2252 - acc: 0.9454 - val_loss: 1.6419 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00026: val_acc improved from 0.64479 to 0.64865, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 27/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.2187 - acc: 0.9477 - val_loss: 1.7044 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00027: val_acc did not improve from 0.64865\n",
      "Epoch 28/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2123 - acc: 0.9488 - val_loss: 1.8596 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00028: val_acc did not improve from 0.64865\n",
      "Epoch 29/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.2058 - acc: 0.9509 - val_loss: 1.7637 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00029: val_acc did not improve from 0.64865\n",
      "Epoch 30/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1992 - acc: 0.9527 - val_loss: 1.7978 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00030: val_acc did not improve from 0.64865\n",
      "Epoch 31/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1951 - acc: 0.9547 - val_loss: 1.7522 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00031: val_acc improved from 0.64865 to 0.64961, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 32/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1906 - acc: 0.9542 - val_loss: 1.9964 - val_acc: 0.6380\n",
      "\n",
      "Epoch 00032: val_acc did not improve from 0.64961\n",
      "Epoch 33/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1874 - acc: 0.9570 - val_loss: 1.8488 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00033: val_acc did not improve from 0.64961\n",
      "Epoch 34/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1825 - acc: 0.9561 - val_loss: 1.8410 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00034: val_acc did not improve from 0.64961\n",
      "Epoch 35/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1792 - acc: 0.9569 - val_loss: 1.9113 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00035: val_acc did not improve from 0.64961\n",
      "Epoch 36/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1741 - acc: 0.9567 - val_loss: 1.8364 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00036: val_acc did not improve from 0.64961\n",
      "Epoch 37/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1705 - acc: 0.9597 - val_loss: 1.8299 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00037: val_acc did not improve from 0.64961\n",
      "Epoch 38/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1675 - acc: 0.9594 - val_loss: 1.9727 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00038: val_acc did not improve from 0.64961\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1622 - acc: 0.9626 - val_loss: 2.0208 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00039: val_acc did not improve from 0.64961\n",
      "Epoch 40/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1618 - acc: 0.9635 - val_loss: 1.9109 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00040: val_acc did not improve from 0.64961\n",
      "Epoch 41/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1589 - acc: 0.9626 - val_loss: 1.9489 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00041: val_acc did not improve from 0.64961\n",
      "Epoch 42/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1533 - acc: 0.9651 - val_loss: 1.8802 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00042: val_acc improved from 0.64961 to 0.65058, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 43/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1522 - acc: 0.9648 - val_loss: 1.9260 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00043: val_acc did not improve from 0.65058\n",
      "Epoch 44/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1493 - acc: 0.9650 - val_loss: 2.0647 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00044: val_acc did not improve from 0.65058\n",
      "Epoch 45/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1459 - acc: 0.9654 - val_loss: 2.1289 - val_acc: 0.6419\n",
      "\n",
      "Epoch 00045: val_acc did not improve from 0.65058\n",
      "Epoch 46/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1436 - acc: 0.9665 - val_loss: 2.0570 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00046: val_acc did not improve from 0.65058\n",
      "Epoch 47/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1391 - acc: 0.9671 - val_loss: 2.1107 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00047: val_acc did not improve from 0.65058\n",
      "Epoch 48/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1383 - acc: 0.9698 - val_loss: 2.0677 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00048: val_acc did not improve from 0.65058\n",
      "Epoch 49/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1345 - acc: 0.9701 - val_loss: 2.0273 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00049: val_acc did not improve from 0.65058\n",
      "Epoch 50/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1338 - acc: 0.9702 - val_loss: 2.1330 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00050: val_acc did not improve from 0.65058\n",
      "Epoch 51/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1326 - acc: 0.9689 - val_loss: 2.2325 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00051: val_acc did not improve from 0.65058\n",
      "Epoch 52/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1277 - acc: 0.9714 - val_loss: 2.2345 - val_acc: 0.6400\n",
      "\n",
      "Epoch 00052: val_acc did not improve from 0.65058\n",
      "Epoch 53/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1258 - acc: 0.9706 - val_loss: 2.0034 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00053: val_acc did not improve from 0.65058\n",
      "Epoch 54/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1260 - acc: 0.9733 - val_loss: 2.1478 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00054: val_acc did not improve from 0.65058\n",
      "Epoch 55/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1219 - acc: 0.9730 - val_loss: 2.0262 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00055: val_acc did not improve from 0.65058\n",
      "Epoch 56/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1213 - acc: 0.9735 - val_loss: 2.1931 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00056: val_acc did not improve from 0.65058\n",
      "Epoch 57/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1190 - acc: 0.9717 - val_loss: 2.1715 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00057: val_acc did not improve from 0.65058\n",
      "Epoch 58/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1177 - acc: 0.9739 - val_loss: 2.2597 - val_acc: 0.6409\n",
      "\n",
      "Epoch 00058: val_acc did not improve from 0.65058\n",
      "Epoch 59/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1160 - acc: 0.9739 - val_loss: 2.1331 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00059: val_acc did not improve from 0.65058\n",
      "Epoch 60/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1150 - acc: 0.9748 - val_loss: 2.0959 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00060: val_acc improved from 0.65058 to 0.65251, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 61/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1131 - acc: 0.9759 - val_loss: 2.2621 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00061: val_acc did not improve from 0.65251\n",
      "Epoch 62/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1114 - acc: 0.9755 - val_loss: 2.1767 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00062: val_acc did not improve from 0.65251\n",
      "Epoch 63/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1103 - acc: 0.9763 - val_loss: 2.2574 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00063: val_acc did not improve from 0.65251\n",
      "Epoch 64/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1079 - acc: 0.9767 - val_loss: 2.1633 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00064: val_acc did not improve from 0.65251\n",
      "Epoch 65/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.1069 - acc: 0.9770 - val_loss: 2.2370 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00065: val_acc did not improve from 0.65251\n",
      "Epoch 66/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1075 - acc: 0.9768 - val_loss: 2.1307 - val_acc: 0.6515\n",
      "\n",
      "Epoch 00066: val_acc did not improve from 0.65251\n",
      "Epoch 67/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1061 - acc: 0.9765 - val_loss: 2.2325 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00067: val_acc did not improve from 0.65251\n",
      "Epoch 68/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1028 - acc: 0.9783 - val_loss: 2.1289 - val_acc: 0.6525\n",
      "\n",
      "Epoch 00068: val_acc did not improve from 0.65251\n",
      "Epoch 69/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.1010 - acc: 0.9795 - val_loss: 2.2116 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00069: val_acc did not improve from 0.65251\n",
      "Epoch 70/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0990 - acc: 0.9799 - val_loss: 2.2890 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00070: val_acc did not improve from 0.65251\n",
      "Epoch 71/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0989 - acc: 0.9793 - val_loss: 2.2945 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00071: val_acc did not improve from 0.65251\n",
      "Epoch 72/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0947 - acc: 0.9811 - val_loss: 2.3691 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00072: val_acc did not improve from 0.65251\n",
      "Epoch 73/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0954 - acc: 0.9805 - val_loss: 2.2594 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00073: val_acc did not improve from 0.65251\n",
      "Epoch 74/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0947 - acc: 0.9808 - val_loss: 2.3065 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00074: val_acc did not improve from 0.65251\n",
      "Epoch 75/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0941 - acc: 0.9797 - val_loss: 2.2488 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00075: val_acc did not improve from 0.65251\n",
      "Epoch 76/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0928 - acc: 0.9805 - val_loss: 2.2479 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00076: val_acc did not improve from 0.65251\n",
      "Epoch 77/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0922 - acc: 0.9798 - val_loss: 2.2703 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00077: val_acc did not improve from 0.65251\n",
      "Epoch 78/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0899 - acc: 0.9811 - val_loss: 2.4264 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00078: val_acc did not improve from 0.65251\n",
      "Epoch 79/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0889 - acc: 0.9821 - val_loss: 2.3567 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00079: val_acc did not improve from 0.65251\n",
      "Epoch 80/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0881 - acc: 0.9816 - val_loss: 2.4120 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00080: val_acc did not improve from 0.65251\n",
      "Epoch 81/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0881 - acc: 0.9828 - val_loss: 2.4052 - val_acc: 0.6448\n",
      "\n",
      "Epoch 00081: val_acc did not improve from 0.65251\n",
      "Epoch 82/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0858 - acc: 0.9826 - val_loss: 2.2735 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00082: val_acc did not improve from 0.65251\n",
      "Epoch 83/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0844 - acc: 0.9834 - val_loss: 2.4504 - val_acc: 0.6438\n",
      "\n",
      "Epoch 00083: val_acc did not improve from 0.65251\n",
      "Epoch 84/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0845 - acc: 0.9829 - val_loss: 2.4055 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00084: val_acc did not improve from 0.65251\n",
      "Epoch 85/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0828 - acc: 0.9829 - val_loss: 2.3828 - val_acc: 0.6467\n",
      "\n",
      "Epoch 00085: val_acc did not improve from 0.65251\n",
      "Epoch 86/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0832 - acc: 0.9826 - val_loss: 2.4935 - val_acc: 0.6429\n",
      "\n",
      "Epoch 00086: val_acc did not improve from 0.65251\n",
      "Epoch 87/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0806 - acc: 0.9853 - val_loss: 2.3325 - val_acc: 0.6515\n",
      "\n",
      "Epoch 00087: val_acc did not improve from 0.65251\n",
      "Epoch 88/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0805 - acc: 0.9838 - val_loss: 2.3705 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00088: val_acc did not improve from 0.65251\n",
      "Epoch 89/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0804 - acc: 0.9835 - val_loss: 2.4081 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00089: val_acc did not improve from 0.65251\n",
      "Epoch 90/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0794 - acc: 0.9850 - val_loss: 2.2569 - val_acc: 0.6544\n",
      "\n",
      "Epoch 00090: val_acc improved from 0.65251 to 0.65444, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 91/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0783 - acc: 0.9851 - val_loss: 2.4377 - val_acc: 0.6486\n",
      "\n",
      "Epoch 00091: val_acc did not improve from 0.65444\n",
      "Epoch 92/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0773 - acc: 0.9852 - val_loss: 2.3997 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00092: val_acc did not improve from 0.65444\n",
      "Epoch 93/500\n",
      "9324/9324 [==============================] - 30s 3ms/step - loss: 0.0770 - acc: 0.9839 - val_loss: 2.4838 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00093: val_acc did not improve from 0.65444\n",
      "Epoch 94/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0734 - acc: 0.9867 - val_loss: 2.3783 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00094: val_acc did not improve from 0.65444\n",
      "Epoch 95/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0736 - acc: 0.9876 - val_loss: 2.3658 - val_acc: 0.6515\n",
      "\n",
      "Epoch 00095: val_acc did not improve from 0.65444\n",
      "Epoch 96/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0739 - acc: 0.9843 - val_loss: 2.3271 - val_acc: 0.6573\n",
      "\n",
      "Epoch 00096: val_acc improved from 0.65444 to 0.65734, saving model to ../models/15_12\\chess_pieces_inceptionv3_p1.hdf5\n",
      "Epoch 97/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0735 - acc: 0.9858 - val_loss: 2.5189 - val_acc: 0.6458\n",
      "\n",
      "Epoch 00097: val_acc did not improve from 0.65734\n",
      "Epoch 98/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0730 - acc: 0.9855 - val_loss: 2.4238 - val_acc: 0.6496\n",
      "\n",
      "Epoch 00098: val_acc did not improve from 0.65734\n",
      "Epoch 99/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0703 - acc: 0.9877 - val_loss: 2.3415 - val_acc: 0.6506\n",
      "\n",
      "Epoch 00099: val_acc did not improve from 0.65734\n",
      "Epoch 100/500\n",
      "9324/9324 [==============================] - 31s 3ms/step - loss: 0.0705 - acc: 0.9868 - val_loss: 2.5543 - val_acc: 0.6477\n",
      "\n",
      "Epoch 00100: val_acc did not improve from 0.65734\n",
      "Epoch 101/500\n",
      "1200/9324 [==>...........................] - ETA: 23s - loss: 0.0595 - acc: 0.9908"
     ]
    }
   ],
   "source": [
    "#X_train = np.array(X_train)\n",
    "#X_test = np.array(X_test)\n",
    "history = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list,\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o98c0gGA3Wkd"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QX8HjeHx3ddt"
   },
   "outputs": [],
   "source": [
    "## Fine tune some inception layers\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "opt = RMSprop(lr=0.00001)\n",
    "model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rOKA0taT4WAH"
   },
   "outputs": [],
   "source": [
    "# checkpoint\n",
    "filepath=os.path.join(model_folder_name, \"chess_pieces_inceptionv3_p2.hdf5\")\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_acc', patience=100, min_delta= 0.0001)\n",
    "callbacks_list = [checkpoint, early_stopping]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kXGir3oX4aVy"
   },
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "batch_size = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-eivTGHd4i5V"
   },
   "outputs": [],
   "source": [
    "history_2 = model.fit(X_train,\n",
    "          y_train,\n",
    "          epochs=epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1,\n",
    "          callbacks=callbacks_list,\n",
    "          batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIHUJ9yO43-U"
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history_2.history['acc'])\n",
    "plt.plot(history_2.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AUAmKCek49Ws"
   },
   "outputs": [],
   "source": [
    "## Helper method to print a confusion matrix\n",
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rX-e3Cxt5GPW"
   },
   "outputs": [],
   "source": [
    "model.load_weights(os.path.join(model_folder_name, \"chess_pieces_inceptionv3_p2.hdf5\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    optimizer=SGD(lr=0.0001, momentum=0.9),\n",
    "    metrics=['accuracy'],\n",
    ")\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(\"Score: \" + str(score))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "test_predictions = model.predict(X_test, batch_size=batch_size)\n",
    "y_test_pred = [np.argmax(x) for x in test_predictions]\n",
    "cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,title='Normalized confusion matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Classify chess pieces.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "WBC env",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
