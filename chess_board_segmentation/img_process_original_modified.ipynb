{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chess Board Detection and Chess Piece Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.spatial as spatial\n",
    "import scipy.cluster as clstr\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import os, glob, skimage, cv2, shutil\n",
    "\n",
    "SQUARE_SIDE_LENGTH = 227\n",
    "categories = ['bb', 'bk', 'bn', 'bp', 'bq', 'br', 'empty', 'wb', 'wk', 'wn', 'wp', 'wq', 'wr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Board Detection\n",
    "\n",
    "How it works:\n",
    "\n",
    "1. Canny edge detection\n",
    "2. Hough line transform\n",
    "3. calculate intersection points\n",
    "4. Agglomerative clustering of intersection points\n",
    "5. find corners\n",
    "6. perspective shift\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def auto_canny(image, sigma=0.33):\n",
    "    \"\"\"\n",
    "    Canny edge detection with automatic thresholds.\n",
    "    \"\"\"\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(image)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(image, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def hor_vert_lines(lines):\n",
    "    \"\"\"\n",
    "    A line is given by rho and theta. Given a list of lines, returns a list of\n",
    "    horizontal lines (theta=90 deg) and a list of vertical lines (theta=0 deg).\n",
    "    \"\"\"\n",
    "    h = []\n",
    "    v = []\n",
    "    for distance, angle in lines:\n",
    "        if angle < np.pi / 4 or (angle > (np.pi - (np.pi / 4))):\n",
    "            v.append([distance, angle])\n",
    "        else:\n",
    "            h.append([distance, angle])\n",
    "    return h, v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def intersections(h, v):\n",
    "    \"\"\"\n",
    "    Given lists of horizontal and vertical lines in (rho, theta) form, returns list\n",
    "    of (x, y) intersection points.\n",
    "    \"\"\"\n",
    "    points = []\n",
    "    for d1, a1 in h:\n",
    "        for d2, a2 in v:\n",
    "            A = np.array([[np.cos(a1), np.sin(a1)], [np.cos(a2), np.sin(a2)]])\n",
    "            b = np.array([d1, d2])\n",
    "            point = np.linalg.solve(A, b)\n",
    "            points.append(point)\n",
    "            \n",
    "    # print(points)\n",
    "    print(\"Number of points: \" + str(len(points)))\n",
    "    return np.array(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cluster(points, max_dist=50):\n",
    "    \"\"\"\n",
    "    Given a list of points, returns a list of cluster centers.\n",
    "    \"\"\"\n",
    "    Y = spatial.distance.pdist(points)\n",
    "    Z = clstr.hierarchy.single(Y)\n",
    "    T = clstr.hierarchy.fcluster(Z, max_dist, 'distance')\n",
    "    clusters = defaultdict(list)\n",
    "    for i in range(len(T)):\n",
    "        clusters[T[i]].append(points[i])\n",
    "    clusters = clusters.values()\n",
    "    clusters = map(lambda arr: (np.mean(np.array(arr)[:,0]), np.mean(np.array(arr)[:,1])), clusters)\n",
    "    clusters_list = list(clusters)\n",
    "    print(clusters_list)\n",
    "    print(\"Number of clusters: \" + str(len(clusters_list)))\n",
    "    return clusters_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def closest_point(points, loc):\n",
    "    \"\"\"\n",
    "    Returns the list of points, sorted by distance from loc.\n",
    "    \"\"\"\n",
    "    return points[cdist([loc], points).argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_corners(points, img_dim):\n",
    "    \"\"\"\n",
    "    Given a list of points, returns a list containing the four corner points.\n",
    "    \"\"\"\n",
    "    print(\"Image dimensions: \" + str(img_dim))\n",
    "    center_point = closest_point(points, (img_dim[0] / 2, img_dim[1] / 2))\n",
    "    print(\"Closest point to {0}, {1} is {2}, {3}\".format(img_dim[0] / 2, img_dim[1] / 2, center_point[0], center_point[1]))\n",
    "    points.remove(center_point)\n",
    "    center_adjacent_point = closest_point(points, center_point)\n",
    "    points.append(center_point)\n",
    "    grid_dist = spatial.distance.euclidean(np.array(center_point), np.array(center_adjacent_point))\n",
    "    print(\"Grid distance: \" + str(grid_dist))\n",
    "    \n",
    "    img_corners = [(0, 0), (0, img_dim[1]), img_dim, (img_dim[0], 0)]\n",
    "    board_corners = []\n",
    "    tolerance = 0.25 # bigger = more tolerance\n",
    "    for img_corner in img_corners:\n",
    "        while True:\n",
    "            cand_board_corner = closest_point(points, img_corner)\n",
    "            points.remove(cand_board_corner)\n",
    "            cand_board_corner_adjacent = closest_point(points, cand_board_corner)\n",
    "            corner_grid_dist = spatial.distance.euclidean(np.array(cand_board_corner), np.array(cand_board_corner_adjacent))\n",
    "            print(\"Corner grid distance: \" + str(corner_grid_dist))\n",
    "            if corner_grid_dist > (1 - tolerance) * grid_dist and corner_grid_dist < (1 + tolerance) * grid_dist:\n",
    "                print(\"Added board corner: \" + str(cand_board_corner))\n",
    "                points.append(cand_board_corner)\n",
    "                board_corners.append(cand_board_corner)\n",
    "                break\n",
    "    return board_corners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(img, points, square_length=SQUARE_SIDE_LENGTH):\n",
    "    board_length = square_length * 8\n",
    "    pts1 = np.float32(points)\n",
    "    pts2 = np.float32([[0, 0], [0, board_length], [board_length, board_length], [board_length, 0]])\n",
    "    M = cv2.getPerspectiveTransform(pts1, pts2)\n",
    "    return cv2.warpPerspective(img, M, (board_length, board_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def find_board(fname, outputs_folder_name):\n",
    "    \"\"\"\n",
    "    Given a filename, returns the board image.\n",
    "    \"\"\"\n",
    "    start = time()\n",
    "    img = cv2.imread(fname)\n",
    "    assert img is not None\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray = cv2.blur(gray, (3, 3)) # TODO auto adjust the size of the blur\n",
    "    \n",
    "    # Canny edge detection\n",
    "    edges = auto_canny(gray)\n",
    "    # assert np.count_nonzero(edges) / float(gray.shape[0] * gray.shape[1]) < 0.015\n",
    "\n",
    "    # Hough line detection\n",
    "    lines = cv2.HoughLines(edges, 1, np.pi/180, 200)\n",
    "    print(lines.shape)\n",
    "    \n",
    "    lines = np.reshape(lines, (-1, 2))\n",
    "    print(lines.shape)\n",
    "    \n",
    "    # Compute intersection points\n",
    "    h, v = hor_vert_lines(lines)\n",
    "    print(h)\n",
    "    print(v)\n",
    "    #assert len(h) >= 9\n",
    "    #assert len(v) >= 9\n",
    "    \n",
    "    print(\"Number of horizontal lines: \" + str(len(h)))\n",
    "    print(\"Number of vertical lines: \" + str(len(v)))\n",
    "    points = intersections(h, v)\n",
    "        \n",
    "    if True:\n",
    "        for rho, theta in lines:\n",
    "            a = np.cos(theta)\n",
    "            b = np.sin(theta)\n",
    "            x0 = a*rho\n",
    "            y0 = b*rho\n",
    "            x1 = int(x0 + 4000*(-b))\n",
    "            y1 = int(y0 + 4000*(a))\n",
    "            x2 = int(x0 - 4000*(-b))\n",
    "            y2 = int(y0 - 4000*(a))\n",
    "            cv2.line(img,(x1,y1),(x2,y2),(0,0,255),2)\n",
    "        cv2.imwrite('H:\\\\AR-ExtendingOnlineGames\\\\ExtendingGames_Code\\\\chess_board_segmentation\\\\outputs\\\\' + outputs_folder_name + '\\\\lines.jpg', img)\n",
    "    \n",
    "    # Cluster intersection points\n",
    "    points = cluster(points)\n",
    "    \n",
    "    if True:\n",
    "        for point in points:\n",
    "            cv2.circle(img, tuple(point), 5, (0,0,255), -1)\n",
    "        cv2.imwrite('H:\\\\AR-ExtendingOnlineGames\\\\ExtendingGames_Code\\\\chess_board_segmentation\\\\outputs\\\\' + outputs_folder_name + '\\\\all_points.jpg', img)\n",
    "    \n",
    "    # Find corners\n",
    "    img_shape = np.shape(img)\n",
    "    corner_points = find_corners(points, (img_shape[1], img_shape[0]))\n",
    "    \n",
    "    if True:\n",
    "        for point in corner_points:\n",
    "            cv2.circle(img, tuple(point), 5, (0,255,0), -1)\n",
    "        cv2.imwrite('H:\\\\AR-ExtendingOnlineGames\\\\ExtendingGames_Code\\\\chess_board_segmentation\\\\outputs\\\\' + outputs_folder_name + '\\\\corner_points.jpg', img)\n",
    "    \n",
    "    # Perspective transform\n",
    "    new_img = four_point_transform(img, corner_points)\n",
    "\n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_board(img):\n",
    "    \"\"\"\n",
    "    Given a board image, returns an array of 64 smaller images.\n",
    "    \"\"\"\n",
    "    arr = []\n",
    "    sq_len = img.shape[0] // 8\n",
    "    for i in range(8):\n",
    "        for j in range(8):\n",
    "            arr.append(img[i * sq_len : (i + 1) * sq_len, j * sq_len : (j + 1) * sq_len])\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#board = find_board('H:\\\\AR-ExtendingOnlineGames\\\\data\\\\chess_board\\\\google\\\\Chess_Board.png', \"22_12\")\n",
    "#cv2.imwrite('H:\\\\AR-ExtendingOnlineGames\\\\ExtendingGames_Code\\\\chess_board_segmentation\\\\outputs\\\\22_12\\\\crop.jpg', board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22, 1, 2)\n",
      "(22, 2)\n",
      "[[749.0, 1.5707964], [69.0, 1.5707964], [409.0, 1.5707964], [493.0, 1.5707964], [577.0, 1.5707964], [325.0, 1.5707964], [241.0, 1.5707964], [661.0, 1.5707964], [156.0, 1.5707964], [72.0, 1.5707964], [745.0, 1.5707964]]\n",
      "[[78.0, 0.0], [759.0, 0.0], [502.0, 0.0], [418.0, 0.0], [334.0, 0.0], [250.0, 0.0], [166.0, 0.0], [671.0, 0.0], [587.0, 0.0], [82.0, 0.0], [755.0, 0.0]]\n",
      "Number of horizontal lines: 11\n",
      "Number of vertical lines: 11\n",
      "Number of points: 121\n",
      "[(80.0, 747.0), (757.0, 747.00006), (502.0, 747.0), (418.0, 747.0), (334.0, 747.0), (250.0, 747.0), (166.0, 747.0), (671.0, 747.0), (587.0, 747.0), (80.0, 70.5), (757.0, 70.50003), (502.0, 70.50002), (418.0, 70.500015), (334.0, 70.500015), (250.0, 70.50001), (166.0, 70.50001), (671.0, 70.50003), (587.0, 70.50002), (80.0, 409.0), (757.0, 409.00003), (502.0, 409.00003), (418.0, 409.00003), (334.0, 409.0), (250.0, 409.0), (166.0, 409.0), (671.0, 409.00003), (587.0, 409.00003), (80.0, 493.0), (757.0, 493.00003), (502.0, 493.00003), (418.0, 493.00003), (334.0, 493.0), (250.0, 493.0), (166.0, 493.0), (671.0, 493.00003), (587.0, 493.00003), (80.0, 577.0), (757.0, 577.00006), (502.0, 577.0), (418.0, 577.0), (334.0, 577.0), (250.0, 577.0), (166.0, 577.0), (671.0, 577.0), (587.0, 577.0), (80.0, 325.0), (757.0, 325.00003), (502.0, 325.00003), (418.0, 325.00003), (334.0, 325.0), (250.0, 325.0), (166.0, 325.0), (671.0, 325.00003), (587.0, 325.00003), (80.0, 241.0), (757.0, 241.00003), (502.0, 241.00002), (418.0, 241.00002), (334.0, 241.00002), (250.0, 241.00002), (166.0, 241.0), (671.0, 241.00003), (587.0, 241.00003), (80.0, 661.0), (757.0, 661.00006), (502.0, 661.0), (418.0, 661.0), (334.0, 661.0), (250.0, 661.0), (166.0, 661.0), (671.0, 661.0), (587.0, 661.0), (80.0, 156.0), (757.0, 156.00003), (502.0, 156.00002), (418.0, 156.00002), (334.0, 156.00002), (250.0, 156.00002), (166.0, 156.0), (671.0, 156.00003), (587.0, 156.00003)]\n",
      "Number of clusters: 81\n",
      "Image dimensions: (835, 817)\n",
      "Closest point to 417.5, 408.5 is 418.0, 409.0000305175781\n",
      "Grid distance: 84.0\n",
      "Corner grid distance: 85.5\n",
      "Added board corner: (80.0, 70.5)\n",
      "Corner grid distance: 86.0\n",
      "Added board corner: (80.0, 747.0)\n",
      "Corner grid distance: 86.0\n",
      "Added board corner: (757.0, 747.00006)\n",
      "Corner grid distance: 85.5\n",
      "Added board corner: (757.0, 70.50003)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board = find_board('H:\\\\AR-ExtendingOnlineGames\\\\data\\\\chess_board\\\\image-14.png', \"1600\")\n",
    "cv2.imwrite('H:\\\\AR-ExtendingOnlineGames\\\\ExtendingGames_Code\\\\chess_board_segmentation\\\\outputs\\\\1600\\\\crop.jpg', board)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Training/Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = {}\n",
    "with open('./labels.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        if line[0] == '#':\n",
    "            continue\n",
    "        arr = line.split()\n",
    "        assert len(arr) == 2\n",
    "        assert arr[0] not in labels\n",
    "        labels[arr[0]] = arr[1]\n",
    "\n",
    "def get_label_arr(key):\n",
    "    \"\"\"\n",
    "    Get the list of piece labels for the specific image number.\n",
    "    \n",
    "    key: The image number\n",
    "    returns: List of piece labels, e.g. ['empty', 'wn', 'empty', ...]\n",
    "    \"\"\"\n",
    "    fen = labels[key]\n",
    "    fen = fen.replace('1', '_')\n",
    "    fen = fen.replace('2', '__')\n",
    "    fen = fen.replace('3', '___')\n",
    "    fen = fen.replace('4', '____')\n",
    "    fen = fen.replace('5', '_____')\n",
    "    fen = fen.replace('6', '______')\n",
    "    fen = fen.replace('7', '_______')\n",
    "    fen = fen.replace('8', '________')\n",
    "    fen = fen.replace('/', '')\n",
    "    arr = []\n",
    "    for char in fen:\n",
    "        if char == '_':\n",
    "            arr.append('empty')\n",
    "        elif char == 'x':\n",
    "            arr.append('del')\n",
    "        elif char.islower():\n",
    "            arr.append('b' + char.lower())\n",
    "        else:\n",
    "            arr.append('w' + char.lower())\n",
    "    assert len(arr) == 64\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0%\n",
      "20.0%\n",
      "30.0%\n",
      "40.0%\n",
      "50.0%\n",
      "60.0%\n",
      "70.0%\n",
      "80.0%\n",
      "90.0%\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DIRS = {'input': './pictures_train/', 'intermediate': './crops_train/', 'output': './output_train/'}\n",
    "TEST_DIRS = {'input': './pictures_test/', 'intermediate': './crops_test/', 'output': './output_test/'}\n",
    "\n",
    "M_90deg_rotation = cv2.getRotationMatrix2D((SQUARE_SIDE_LENGTH / 2, SQUARE_SIDE_LENGTH / 2), 90, 1)\n",
    "\n",
    "def write_augmented_output(output_dir, img_num, images, labels):\n",
    "    for i in range(len(images)):\n",
    "        if labels[i] == 'del':\n",
    "            continue\n",
    "        if not os.path.exists(output_dir + labels[i]):\n",
    "            os.makedirs(output_dir + labels[i])\n",
    "        img_90 = cv2.warpAffine(images[i], M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        img_180 = cv2.warpAffine(img_90, M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        img_270 = cv2.warpAffine(img_180, M_90deg_rotation, (SQUARE_SIDE_LENGTH, SQUARE_SIDE_LENGTH))\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '.jpg', images[i])\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_90.jpg', img_90)\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_180.jpg', img_180)\n",
    "        cv2.imwrite(output_dir + labels[i] + '/' + img_num + '_' + str(i) + '_270.jpg', img_270)\n",
    "\n",
    "def gen_data(dir_dict):\n",
    "    for path in dir_dict.values():\n",
    "        assert path[-1] == '/'\n",
    "    shutil.rmtree(dir_dict['intermediate'], True)\n",
    "    shutil.rmtree(dir_dict['output'], True)\n",
    "    os.makedirs(dir_dict['intermediate'])\n",
    "    os.makedirs(dir_dict['output'])\n",
    "    \n",
    "    input_paths = glob.glob(dir_dict['input'] + '*.jpg')\n",
    "    percent = 0\n",
    "    for i in range(len(input_paths)):\n",
    "        new_percent = 100 * float(i) / len(input_paths)\n",
    "        if new_percent > percent + 5:\n",
    "            percent = new_percent\n",
    "            print(str(percent) + '%')\n",
    "        \n",
    "        input_path = input_paths[i]\n",
    "        input_img_num = input_path[input_path.rfind('_') + 1 : input_path.rfind('.')]\n",
    "        board = find_board(input_path)\n",
    "        cv2.imwrite(dir_dict['intermediate'] + input_img_num + '.jpg', board)\n",
    "        piece_images = split_board(board)\n",
    "        piece_labels = get_label_arr(input_img_num)\n",
    "        write_augmented_output(dir_dict['output'], input_img_num, piece_images, piece_labels)\n",
    "    print('Done')\n",
    "\n",
    "\n",
    "gen_data(TEST_DIRS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Caffe list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "def get_label_for_fname(fname):\n",
    "    for i in range(len(categories)):\n",
    "        if '/' + categories[i] + '/' in fname:\n",
    "            return str(i)\n",
    "    raise\n",
    "\n",
    "fnames = glob.glob(TRAIN_DIRS['output'] + '*/*.jpg')\n",
    "fnames = shuffle(map(os.path.abspath, fnames))\n",
    "with open('caffe_train.txt', 'w+') as f:\n",
    "    for fname in fnames:\n",
    "        f.write(fname + ' ' + get_label_for_fname(fname) + '\\n')\n",
    "        \n",
    "fnames = glob.glob(TEST_DIRS['output'] + '*/*.jpg')\n",
    "fnames = shuffle(map(os.path.abspath, fnames))\n",
    "with open('caffe_test.txt', 'w+') as f:\n",
    "    for fname in fnames:\n",
    "        f.write(fname + ' ' + get_label_for_fname(fname) + '\\n')\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 131.33953259  145.51087425  134.98660675]\n"
     ]
    }
   ],
   "source": [
    "# Compute mean\n",
    "\n",
    "fnames = glob.glob(TRAIN_DIRS['intermediate'] + '*.jpg')\n",
    "means = None\n",
    "for fname in fnames:\n",
    "    this_mean = np.mean(np.reshape(cv2.imread(fname), (-1, 3)), axis=0)\n",
    "    if means is None:\n",
    "        means = this_mean\n",
    "    else:\n",
    "        means = np.vstack((means, this_mean))\n",
    "means = np.mean(means, axis=0) # bgr\n",
    "print(means)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting boards with the Caffe model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = caffe.Net('/Users/daylenyang/caffe/models/finetune_chess/deploy.prototxt',\n",
    "               '/Users/daylenyang/caffe/models/finetune_chess/finetune_chess_iter_5554.caffemodel',\n",
    "               caffe.TEST)\n",
    "\n",
    "transformer = caffe.io.Transformer({'data': net.blobs['data'].data.shape})\n",
    "transformer.set_transpose('data', (2,0,1))\n",
    "transformer.set_mean('data', np.load('/Users/daylenyang/caffe/python/caffe/imagenet/ilsvrc_2012_mean.npy').mean(1).mean(1)) # mean pixel\n",
    "transformer.set_raw_scale('data', 255)  # the reference model operates on images in [0,255] range instead of [0,1]\n",
    "transformer.set_channel_swap('data', (2,1,0))  # the reference model has channels in BGR order instead of RGB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shrink_blanks(fen):\n",
    "    if '_' not in fen:\n",
    "        return fen\n",
    "    new_fen = ''\n",
    "    blanks = 0\n",
    "    for char in fen:\n",
    "        if char == '_':\n",
    "            blanks += 1\n",
    "        else:\n",
    "            if blanks != 0:\n",
    "                new_fen += str(blanks)\n",
    "                blanks = 0\n",
    "            new_fen += char\n",
    "    if blanks != 0:\n",
    "        new_fen += str(blanks)\n",
    "    return new_fen\n",
    "\n",
    "def get_fen(arr):\n",
    "    fen = ''\n",
    "    for sq in arr:\n",
    "        if sq == 'empty':\n",
    "            fen += '_'\n",
    "        elif sq[0] == 'b':\n",
    "            fen += sq[1]\n",
    "        else:\n",
    "            fen += str(sq[1]).upper()\n",
    "    fens = [fen[i:i+8] for i in range(0, 64, 8)]\n",
    "    fens = map(shrink_blanks, fens)\n",
    "    fen = '/'.join(fens)\n",
    "    return fen\n",
    "\n",
    "def get_square_to_pieces_dict(prob_matrix):\n",
    "    d = {}\n",
    "    for i in range(len(prob_matrix)):\n",
    "        d[i] = map(lambda x: categories[x], np.argsort(-prob_matrix[i]))\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished board splitting 0.352416992188 sec\n",
      "finished input preprocessing 0.775801897049 sec\n",
      "8/5k2/r7/3N1NPP/8/8/8/8\n",
      "finished nn 1.6532959938 sec\n",
      "took 1.65340399742 sec\n"
     ]
    }
   ],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "start = time()\n",
    "\n",
    "board = find_board('./pictures_test/IMG_0983.jpg')\n",
    "squares = split_board(board)\n",
    "#print('finished board splitting'+ time() - start+ 'sec')\n",
    "net.blobs['data'].reshape(64,3,227,227)\n",
    "input_images = [transformer.preprocess('data', skimage.img_as_float(square).astype(np.float32)) for square in squares]\n",
    "#print('finished input preprocessing', time() - start, 'sec')\n",
    "net.blobs['data'].data[...] = np.array(input_images)\n",
    "out = net.forward()['prob']\n",
    "#print get_fen(map(lambda x: categories[x], np.argmax(out, axis=1)))\n",
    "#print('finished nn', time() - start, 'sec')\n",
    "    \n",
    "#print 'took', time() - start, 'sec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
